phrsae_encoder_tokenizer: 
    zh: /apdcephfs/share_916081/johntianlan/bert-base-chinese
    en: /apdcephfs/share_916081/johntianlan/bert-base-cased
phrase_encoder_model: 
    zh: /apdcephfs/share_916081/johntianlan/bert-base-chinese
    en: /apdcephfs/share_916081/johntianlan/bert-base-cased
prefix_encoder_tokenizer: 
    zh: /apdcephfs/share_916081/johntianlan/gpt2-chinese-cluecorpussmall
    en: /apdcephfs/share_916081/johntianlan/gpt2_english
prefix_encoder_model: 
    zh: /apdcephfs/share_916081/johntianlan/gpt2-chinese-cluecorpussmall
    en: /apdcephfs/share_916081/johntianlan/gpt2_english

# train configuration
train:
    dropout: 0.1
    load_param: true
    lr: 0.00005
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_len: 512 
    warmup_ratio: 0.
    iter_to_accumulate: 1
    max_doc_size: 256
    buffer_size: 81920
    total_step: 200010
    save_every: 10000
    temp: 0.07
    min_phrase_length: 1
    max_phrase_length: 16
    doc_max_length: 128

# test configuration
test:
    seed: 0
    batch_size: 1
    prefix_length_rate: 0.5
    max_gen_len: 512
